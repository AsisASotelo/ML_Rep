{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A group of predictors is called an ensemble; thus, this technique is called **Ensemble Learning** , and an Ensemble Learning Algorithm is called a an **Ensemble Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have trained a few classifiers, each one achieving about 80% accuracy. You may have a Logistic Regression classifier, an SVM classifier, a Random Forest classifer, a K-Nearest Neighbors classifier, and perhaps a few more.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "heads_proba= .51 # Define the probability of heads \n",
    "coin_tosses = (np.random.rand(1,000,10)<heads_proba).astype(np.int32) # The np.random.rand() function returns a 10,000 rows with 10 random numbers as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing the train_test_split is required to create training samples.\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=.30,random_state=42)\n",
    "\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X ,y, random_state=42)\n",
    "\n",
    "# Splitting of Training and Testing Set is Seperated with a Random Seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.35"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr',log_clf), ('rf',rnd_clf),('svc',svm_clf)],\n",
    "    voting = 'hard'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at each classifiers accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.888\n",
      "SVC 0.896\n",
      "VotingClassifier 0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()),\n",
       "                             ('svc', SVC(probability=True))],\n",
       "                 voting='soft')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr',log_clf), ('rf',rnd_clf),('svc',svm_clf)],\n",
    "    voting = 'soft'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Pasting in Scikit-Learn"
   ]
  },
  {
   "source": [
    "One way to get a diverse set of classifiers is very different training algorithms, as just discussed. Another approach is to use the same training algorithm for every, but to train them on different random subsets of the training set. When sampling is performed with replacement, this method is called bagging (short for bootstrap). When the sampling is done without replacement it is called Pasting."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf=BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500, max_samples=100,bootstrap=True,n_jobs=-1\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train,y_train)\n",
    "y_pred=bag_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "source": [
    "## Out of Bag Evaluation\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),n_estimators=500,\n",
    "    bootstrap=True,n_jobs=-1,oob_score=True\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train,y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "source": [
    "According to this metric this Bagging Classifier is likely to achieve about 93.1 accuracy on the test set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "source": [
    "# Random Forests"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf=RandomForestClassifier(n_estimators=500,max_leaf_nodes=16,n_jobs=-1)\n",
    "rnd_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred_rf=rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "source": [
    "## A Bagging Classifer Equivalent to the Previous Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bagging Classifier With A Decision Classifier Only\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(splitter=\"random\",max_leaf_nodes=16),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "source": [
    "## Using Random Forests For Feature Importances"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sepal length (cm) 0.09182141447733241\nsepal width (cm) 0.024958852212837314\npetal length (cm) 0.4513550547973911\npetal width (cm) 0.4318646785124392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()\n",
    "rnd_clf=RandomForestClassifier(n_estimators=500,n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"],iris[\"target\"])\n",
    "\n",
    "for name,score in zip(iris[\"feature_names\"],rnd_clf.feature_importances_):\n",
    "    print(name,score)\n"
   ]
  },
  {
   "source": [
    "# Ada Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A sequential training of predictors where the instances have weights attributed to them based on the predictors ability to accurately classify them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.5, n_estimators=200)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf=AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=1),\n",
    "        n_estimators=200,\n",
    "        algorithm=\"SAMME.R\",\n",
    "        learning_rate=.5\n",
    "        )\n",
    "ada_clf.fit(X_train,y_train)"
   ]
  },
  {
   "source": [
    "# Gradient Boosting\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Gradient boosting is training sequential Predictors that do a better job at reducing the residual errors of the predicotrs. This is opposed to the AdaBoost which changes the weights of the instances."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Train a Decision Tree Regressor to the training set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1=DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X,y)"
   ]
  },
  {
   "source": [
    "Train a second Decision Tree Regressor on the residual errors made by the first predictor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X,y2)"
   ]
  },
  {
   "source": [
    "We then train a third regressor on the residual errors made by the second preditor:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "y3= y2 - tree_reg2.predict(X)\n",
    "tree_reg3=DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 8.31039149e-01 -2.58748754e-01]\n [ 1.18506381e+00  9.20387143e-01]\n [ 1.16402213e+00 -4.55525583e-01]\n [-2.36556013e-02  1.08628844e+00]\n [ 4.80502733e-01  1.50942444e+00]\n [ 1.31164912e+00 -5.51176060e-01]\n [ 1.16542367e+00 -1.58629894e-01]\n [ 1.56736404e-01  1.31817168e+00]\n [ 4.53301022e-01  4.96074925e-01]\n [ 1.65139719e+00 -4.59804351e-01]\n [ 1.02664982e+00 -1.56999382e-02]\n [-3.99677570e-01  2.52192940e-01]\n [ 1.85352710e+00 -7.16418704e-01]\n [ 1.17564737e-01  6.24869329e-01]\n [ 1.54123944e+00 -5.11050694e-01]\n [ 1.32833559e+00 -5.40696860e-01]\n [ 1.97170320e+00  2.97790052e-01]\n [ 9.44441260e-01  5.17911799e-01]\n [ 8.30619129e-01 -8.02099114e-01]\n [ 1.89343763e+00 -2.53611270e-01]\n [ 1.88323111e+00  2.22375278e-01]\n [ 2.30801311e+00  4.67930154e-01]\n [-3.89437608e-01  2.39389050e-01]\n [ 1.11201360e+00 -2.15523587e-01]\n [ 3.86380017e-01  4.15946340e-01]\n [ 1.78946151e+00  1.01491329e+00]\n [ 1.53618196e+00  2.21948473e-01]\n [-7.69640886e-01  4.23924672e-01]\n [ 2.32109137e-01  1.56378251e+00]\n [ 2.54988025e-01 -3.76548892e-01]\n [ 2.01507630e+00 -3.96189166e-02]\n [ 1.00933981e-01 -3.03530559e-01]\n [ 2.27959897e+00 -5.61509423e-02]\n [-5.47415602e-01  8.43367662e-01]\n [ 9.22156327e-01  3.80275694e-01]\n [ 3.48367318e-01 -7.73061049e-01]\n [ 9.47168956e-01 -3.83048924e-01]\n [ 9.52905753e-01  8.44005843e-01]\n [-9.70543017e-01  6.21054075e-01]\n [ 7.56247838e-01  9.61623255e-01]\n [ 1.51752434e+00 -7.79142429e-01]\n [-3.14828672e-01  8.16597563e-01]\n [ 1.67863799e+00  5.73868804e-01]\n [-9.08623297e-01  1.59812110e-01]\n [ 7.42308460e-01 -4.31621580e-02]\n [ 1.04111175e+00  9.67223360e-01]\n [ 1.19426743e+00  1.60807960e-01]\n [ 1.24243613e+00  4.78342723e-01]\n [ 1.32711038e+00 -7.98253217e-01]\n [ 7.07643904e-01  2.60445002e-01]\n [-1.54304150e-01  1.13134609e+00]\n [-1.23250997e+00  9.27916869e-01]\n [-1.32338788e-01  1.08219171e+00]\n [ 1.29149569e+00 -3.36197576e-01]\n [-9.02174035e-01  4.82353824e-01]\n [ 4.99570077e-01  1.09730924e+00]\n [-1.82097781e-01  1.01921527e+00]\n [ 7.11654204e-01  1.54701440e-01]\n [-1.13927763e+00  3.90393848e-01]\n [ 1.90864991e-01  1.30952481e+00]\n [ 1.77093903e+00  1.74433997e-01]\n [-3.86243668e-01  1.17814064e-01]\n [ 2.46530946e-01 -3.11068557e-01]\n [ 1.78609681e+00 -1.80684429e-01]\n [ 8.86784019e-02  1.04359771e+00]\n [ 8.44526441e-01  6.67107541e-01]\n [ 2.05623856e+00 -2.39382466e-02]\n [ 4.66738101e-01  6.05212669e-01]\n [-5.70505786e-01  4.11170776e-03]\n [ 1.30886199e+00 -4.82542528e-01]\n [ 1.13163198e+00 -6.63312096e-01]\n [ 9.35868024e-01 -5.24502587e-01]\n [-1.50779941e-01  1.98853850e-01]\n [ 2.27404694e-01  5.89937196e-01]\n [ 4.32375469e-01 -1.90205453e-01]\n [ 7.02094078e-01  5.05056612e-02]\n [-1.67605294e-01  6.81635175e-01]\n [ 4.22511400e-01  5.69916909e-01]\n [ 1.59526999e+00 -3.07936529e-01]\n [ 2.00934560e+00  6.69273873e-03]\n [-1.40711338e+00  8.51051810e-01]\n [ 3.55512740e-01  1.12749583e+00]\n [ 1.79274644e+00  9.87757449e-01]\n [-1.45026364e-01  7.08757656e-01]\n [ 7.19988958e-01 -1.23142918e-01]\n [ 4.91704872e-01  1.14754730e+00]\n [-6.28175768e-01  8.36796439e-01]\n [ 1.72499589e+00  2.37370621e-01]\n [ 3.66024869e-01 -3.41011904e-01]\n [-5.47015167e-01  7.42421951e-01]\n [ 1.00294504e+00 -3.36196323e-01]\n [ 2.51430833e+00  2.34176525e-01]\n [ 7.84541412e-01 -6.16875654e-02]\n [ 5.43313819e-01 -1.27962635e-01]\n [ 1.19704521e+00  1.05274369e-01]\n [ 7.72633023e-01 -8.51886559e-01]\n [ 6.12398431e-01  2.65568153e-01]\n [ 1.28731144e+00  4.80679551e-01]\n [ 2.20170803e+00 -4.39754157e-01]\n [ 1.15021283e+00 -8.55136146e-02]\n [-7.00865433e-01 -7.05956226e-02]\n [ 1.81320639e+00 -2.35239137e-01]\n [ 5.61705076e-01  3.88662624e-01]\n [ 2.34030310e-01  2.50655164e-02]\n [ 4.18355641e-01 -3.82677397e-01]\n [ 1.26548872e+00  1.36369921e+00]\n [ 4.35784764e-01 -1.86108131e-01]\n [-1.08073005e+00  4.06430127e-03]\n [ 2.90737036e-01 -4.35217127e-01]\n [ 4.94790758e-01  9.36359772e-01]\n [-5.24873410e-01  1.00008904e+00]\n [ 1.62787591e+00 -3.07857894e-01]\n [ 7.61917228e-01 -3.57663548e-01]\n [ 1.18128413e+00  7.61136745e-02]\n [ 2.43829239e+00  1.48367062e-01]\n [ 1.95583776e-01 -1.16579470e-01]\n [-8.58133550e-01  2.20550515e-01]\n [-1.33949112e+00 -3.46903179e-01]\n [ 1.82584939e-01  8.48895326e-01]\n [ 9.40830424e-01  1.18142445e-01]\n [-1.40195809e+00  4.19785776e-01]\n [-7.09936154e-01  1.63014835e-01]\n [ 7.68231631e-01 -6.65057388e-01]\n [ 4.20116471e-01  7.48839719e-01]\n [-8.53854570e-01  7.19240644e-01]\n [-5.17893847e-01  8.69860811e-01]\n [ 1.05396355e+00 -7.00407873e-01]\n [-7.68458149e-01  8.00261424e-01]\n [-2.22923603e-02  5.08422712e-01]\n [ 6.05922593e-01 -3.97975225e-01]\n [ 8.62610227e-01 -3.02159223e-01]\n [ 3.83830344e-01  1.03305359e+00]\n [ 2.47235568e+00  1.19868769e-01]\n [ 2.04797386e-01  4.87680968e-01]\n [-7.18165328e-01  1.76594880e+00]\n [ 6.23121786e-01  8.07122726e-01]\n [-5.60184900e-01  4.14317507e-01]\n [ 1.50859816e+00  3.77984492e-01]\n [ 9.13044082e-01  2.54397863e-01]\n [ 2.47130540e-01  3.15114587e-01]\n [ 9.37451497e-01  2.34296809e-01]\n [-1.09355336e+00 -1.47113258e-01]\n [ 2.56743410e+00  8.45530241e-01]\n [ 5.63371156e-01  6.23083015e-01]\n [ 7.17679727e-01  2.80834180e-01]\n [-4.36556097e-02  3.47358895e-01]\n [ 1.09364509e+00  4.79272454e-01]\n [-7.37347663e-01  2.90746946e-01]\n [ 2.10045505e-01  3.04897587e-01]\n [ 1.77879206e+00 -1.47037158e-01]\n [ 1.22686504e+00  2.54432366e-01]\n [-2.56920403e-02  1.13186802e+00]\n [ 1.03912879e+00  1.50405590e-01]\n [ 8.97480164e-01  3.82935294e-01]\n [ 2.40579035e+00  2.97418559e-01]\n [ 1.31270833e+00 -5.95235739e-01]\n [ 1.07434090e+00  2.79562067e-01]\n [-1.62238743e+00  8.34466868e-01]\n [ 8.17113372e-01 -1.27786416e-01]\n [ 9.32941989e-01 -1.51265895e-02]\n [-5.04793000e-01  1.41305691e+00]\n [ 7.10423148e-01 -5.20759286e-01]\n [ 1.36033430e+00 -1.26924940e-01]\n [ 9.29983069e-01  6.74097501e-01]\n [ 1.85320790e+00  2.70036334e-01]\n [ 2.22926924e+00  3.70262825e-01]\n [ 8.41038947e-01  1.94589699e-01]\n [ 9.80574816e-01  6.40486018e-01]\n [ 1.71437491e+00  2.98215037e-02]\n [-4.66763460e-01  1.18115176e+00]\n [ 1.57016209e+00  1.69960064e-01]\n [ 5.53679994e-01  9.71774175e-01]\n [ 1.22017195e+00  2.58504616e-01]\n [ 4.81049120e-01  1.59643427e+00]\n [ 3.47519206e-01  1.46151610e+00]\n [-9.48242964e-01  5.99715840e-01]\n [ 4.77238088e-01 -6.81339845e-01]\n [-4.25417774e-01  8.20296921e-01]\n [ 1.68008833e-02  6.88933176e-01]\n [ 6.68005561e-01 -4.36210236e-01]\n [ 1.01352252e+00 -9.03840639e-02]\n [-9.64974470e-01  4.81193749e-01]\n [ 1.48931444e+00 -5.48317186e-01]\n [-3.21149196e-01 -1.40023428e-01]\n [ 2.00443866e+00 -4.45356361e-01]\n [ 2.12471916e-01  7.71289356e-01]\n [ 1.06529157e+00 -6.81949178e-01]\n [ 3.88913391e-01  8.22019976e-01]\n [-5.65828026e-01  3.98229243e-01]\n [-5.41334715e-01  1.09535941e+00]\n [ 2.24929422e+00  4.12823738e-01]\n [ 8.73264409e-01 -4.75183314e-01]\n [ 1.25893422e+00 -3.54797752e-01]\n [-3.20005153e-01  3.09134585e-01]\n [-2.11741640e-02  1.25270510e+00]\n [-1.20166076e+00 -1.83916427e-01]\n [-1.22151383e-01  9.71000956e-01]\n [ 1.08164813e+00  4.28311211e-01]\n [-3.07087513e-01  1.27930459e+00]\n [ 7.32020691e-01 -7.68693626e-01]\n [ 1.65833920e+00 -3.76447643e-01]\n [ 9.04911388e-01  7.67140201e-01]\n [-1.13313494e+00 -5.86783491e-01]\n [-9.19146564e-01  1.31188165e+00]\n [-3.75938497e-01  1.23427610e+00]\n [-4.95533490e-01  2.89638742e-01]\n [-2.36150335e-01  8.46784264e-01]\n [ 4.25777369e-01 -2.66667273e-01]\n [ 1.85814503e+00  3.09624394e-01]\n [ 6.23006877e-01 -5.44865770e-01]\n [-2.48597411e-01  7.76490416e-01]\n [ 8.84269029e-02  1.28304752e+00]\n [ 6.39768552e-01 -8.39048380e-01]\n [-4.60651397e-02 -2.66798449e-01]\n [ 7.73400856e-01  4.81659254e-01]\n [ 9.87997149e-01 -1.03094492e+00]\n [ 1.34717798e+00 -1.59116031e-01]\n [-6.95914537e-01  4.85217743e-01]\n [ 7.35952633e-01 -4.44962923e-01]\n [-1.49012497e+00 -8.20350032e-02]\n [ 1.16376832e+00 -7.10319015e-01]\n [ 2.52147411e-01  3.41836854e-01]\n [ 1.30882068e+00  7.26225254e-01]\n [-7.16454567e-01  8.44354671e-01]\n [ 1.19605271e-01  8.31081154e-01]\n [ 7.69111059e-01 -5.20285586e-01]\n [-1.14067002e+00  3.67748440e-01]\n [ 1.53869929e+00  1.88744130e-01]\n [-8.70156456e-03  2.02969887e-01]\n [ 7.85423542e-01  3.84731868e-01]\n [ 1.63538015e-01  1.08562240e+00]\n [ 4.13783801e-01  4.98547552e-01]\n [ 2.21081291e+00 -1.87456268e-01]\n [ 7.58845273e-01  5.61859153e-01]\n [ 1.00329157e+00 -8.43363338e-01]\n [ 3.34770561e-01 -5.02763154e-01]\n [ 6.44782950e-01 -2.08983980e-01]\n [-1.25137994e-01  1.07387112e+00]\n [ 8.78161267e-02  9.86727945e-01]\n [-8.42890258e-01  7.87523061e-01]\n [ 1.21060366e+00 -1.24634761e+00]\n [-8.50562192e-01  8.25471394e-01]\n [ 1.68026655e+00 -2.83687635e-01]\n [ 1.26546418e+00 -1.49129836e-01]\n [ 1.28282373e+00 -8.97416640e-01]\n [ 1.09617610e+00  8.98727851e-01]\n [ 4.24711922e-01  1.19605397e+00]\n [ 7.61642000e-01  8.97760589e-01]\n [ 4.20154991e-01 -2.58065072e-01]\n [-5.78388188e-01  1.22192588e+00]\n [ 1.99836424e+00  2.60160788e-01]\n [ 3.26043231e-01 -8.45633689e-03]\n [ 2.10662755e+00  1.54286292e-01]\n [-8.14968012e-01  2.64231623e-01]\n [ 2.60055401e-01 -5.74706495e-01]\n [ 1.58506742e+00 -4.50210209e-01]\n [-1.55571986e-01  6.48785009e-01]\n [ 5.83197855e-01 -5.80983314e-01]\n [-5.93855155e-01  4.25809263e-01]\n [ 2.02278725e+00  3.70359595e-01]\n [-1.32088035e-01  2.72172555e-02]\n [-7.34115578e-02  8.02151396e-01]\n [ 1.11720361e+00 -1.93596671e-01]\n [ 9.12988584e-02  9.49474798e-01]\n [ 1.54062055e-01  1.17959385e+00]\n [-7.40742091e-01  5.36229504e-01]\n [ 2.15881305e+00  1.49840044e-01]\n [ 3.83524621e-01  8.25664840e-01]\n [ 1.42969598e+00 -5.77424000e-01]\n [-5.54209197e-01  9.15652870e-01]\n [-5.65614651e-01  5.63577626e-01]\n [-8.87106610e-01  5.12633178e-01]\n [-5.92226723e-01 -6.99897055e-02]\n [ 6.38249038e-01 -9.53307396e-01]\n [ 5.82200723e-01  3.19959599e-01]\n [ 9.78505796e-01 -1.05994162e+00]\n [ 1.45025118e+00 -5.04528124e-01]\n [ 4.96969798e-01 -7.72840771e-02]\n [ 5.23858315e-01 -4.87290233e-01]\n [ 4.63179454e-02  1.41655744e+00]\n [ 5.76656121e-01  1.40806443e-01]\n [-1.74085223e+00  5.41048899e-01]\n [ 1.45626034e+00 -5.43769449e-02]\n [-8.52369635e-01  3.63567348e-01]\n [ 1.35525882e-01  9.46814678e-01]\n [ 1.53576767e+00 -5.06267009e-01]\n [-3.62985763e-01  1.97916474e-01]\n [ 1.52693188e+00 -1.99797808e-01]\n [ 1.10501631e+00 -1.12538622e+00]\n [-4.27567031e-01 -8.44484091e-02]\n [ 8.92815217e-01 -2.46675900e-01]\n [-3.27220550e-01  1.63926424e-01]\n [ 1.19442663e+00 -7.28380683e-01]\n [ 3.83769310e-01 -1.66194429e-01]\n [ 2.39259245e-01  1.00268142e+00]\n [-5.61649293e-01  1.05118960e+00]\n [ 2.18510627e-01 -1.42457079e-01]\n [ 2.00493703e+00 -3.47664858e-01]\n [ 2.17400276e+00  1.98064359e-01]\n [ 1.84956254e+00  2.43629132e-01]\n [ 1.71864629e+00  3.25238155e-02]\n [-9.50729893e-01 -2.49449947e-01]\n [ 4.71263691e-01  5.40285159e-01]\n [-4.45389489e-01  3.65734910e-01]\n [-9.36892162e-02  9.88588591e-01]\n [-8.18524927e-01  8.93634843e-01]\n [ 4.18572020e-01  6.04312317e-01]\n [-1.01700330e+00  5.50549109e-01]\n [-3.28575718e-01  7.78008554e-01]\n [-1.24643060e-01  9.89103494e-01]\n [ 8.35812732e-01 -5.08903882e-01]\n [-1.22247662e+00  6.02671766e-01]\n [ 1.26940638e+00 -4.09771069e-01]\n [ 1.44540168e+00 -4.48312986e-01]\n [-1.85553565e-02  1.30864462e+00]\n [ 1.41337279e-01  3.31462221e-01]\n [ 1.60780938e+00  2.09242334e-01]\n [ 3.41829090e-01  1.16711570e+00]\n [ 1.27375174e+00 -4.79303361e-01]\n [ 2.23925193e-01 -4.53479666e-01]\n [-2.46389750e-01  7.09155675e-01]\n [ 1.92461422e+00 -2.47699157e-01]\n [ 9.08282047e-01  4.79460688e-01]\n [ 1.86887662e+00  1.94377426e-01]\n [ 5.19582397e-01  9.22877588e-01]\n [ 5.55623466e-01  1.98502585e-01]\n [ 2.43361433e-01  6.93859798e-01]\n [-1.07058138e+00 -9.02639925e-02]\n [-9.97738228e-01  7.60088296e-01]\n [ 1.04067847e+00 -4.37338701e-01]\n [-6.57489098e-02  8.35845778e-01]\n [ 6.32934584e-01  3.11565495e-02]\n [ 1.13520113e+00  6.30407956e-01]\n [ 1.09383780e+00  1.58557073e-01]\n [-3.17480070e-01  1.13276953e+00]\n [-4.27631554e-01  9.63252693e-01]\n [ 1.89829119e+00 -6.78328498e-01]\n [ 8.98213525e-02 -2.23066358e-03]\n [-5.97264479e-01  2.08878893e-01]\n [ 3.29765085e-01  5.64050214e-01]\n [ 8.26711105e-01  9.49740216e-01]\n [-1.15634140e+00  3.76438271e-01]\n [ 2.12126228e+00  4.85220205e-01]\n [ 8.98851828e-01 -6.05412408e-01]\n [-1.17892970e+00  6.10705608e-01]\n [ 1.21820800e+00  2.15727178e-01]\n [ 1.76582991e+00  6.79440444e-01]\n [ 1.67443220e+00 -1.25822598e-01]\n [-1.20537442e+00  1.28551662e+00]\n [-2.84324609e-01  1.53414905e-01]\n [-4.63234422e-02  9.35616132e-02]\n [ 1.34461311e+00 -3.83153460e-01]\n [ 8.03734830e-01  3.31613018e-01]\n [-4.56237689e-02  2.19888528e-02]\n [ 1.37218776e+00  8.18834257e-02]\n [-1.41817886e-01  1.04753175e+00]\n [-8.24793752e-01 -1.24749357e-02]\n [ 1.90191944e+00 -7.88098354e-01]\n [-8.09671925e-01  4.26491726e-01]\n [-5.89301101e-01  4.79412580e-01]\n [ 4.70450486e-02  1.43026566e+00]\n [ 5.01692520e-01  2.17172111e-01]\n [-6.27439177e-01  6.69740675e-01]\n [ 6.21163334e-01  7.10148558e-01]\n [ 3.87520161e-01  5.31935505e-01]\n [ 1.27462287e+00  1.94647115e-01]\n [ 3.29856488e-01  3.14630248e-01]\n [ 2.03240025e-02 -6.57926627e-01]\n [-5.39117616e-01  7.45346886e-01]\n [ 1.81516221e+00 -2.02170085e-01]\n [ 1.00570655e+00  5.98193046e-01]\n [ 2.02747486e+00  1.45869269e-01]\n [-8.59816542e-01  1.85851059e-01]\n [ 5.18230797e-02  5.30802196e-01]\n [ 2.68166631e-01  4.31113745e-01]\n [ 1.79050778e-01  8.28569351e-01]\n [ 2.24167277e+00  4.78774577e-02]\n [-1.99751831e-01  1.43509879e+00]\n [ 1.21502811e+00  5.66784271e-01]\n [ 3.87574934e-01  1.31376262e+00]\n [ 6.66423156e-01  8.71813578e-01]\n [ 1.85216228e+00 -3.94130312e-01]\n [ 1.16626859e+00  2.13338784e-01]\n [ 2.56664520e-01 -3.43103751e-01]\n [ 1.50524330e+00  4.20784380e-01]\n [ 5.44413316e-01  1.65076041e+00]\n [ 1.39788388e-01 -3.17710478e-01]\n [ 8.60746492e-01 -2.47869641e-01]\n [-2.42368730e-01  7.96088693e-01]\n [ 1.21470822e+00  4.01097438e-01]\n [ 1.47207791e+00 -2.71151964e-01]\n [ 1.93306095e+00  5.92843874e-01]\n [ 1.63756905e+00  4.47819110e-01]\n [-1.03740547e+00  4.27414971e-01]\n [ 5.36806389e-01 -3.20840280e-01]\n [ 2.07723520e+00 -9.94194471e-02]\n [ 1.37793380e+00 -6.73602990e-01]\n [ 3.42577220e-01 -1.07559161e+00]\n [-1.13344086e+00  3.50051371e-01]\n [-1.00574418e+00  9.21947076e-01]\n [-3.95018323e-01  8.32744841e-01]\n [ 2.26083403e-01 -7.35146688e-01]\n [ 1.65174474e+00 -4.80648239e-02]\n [-2.68080704e-01  4.45531854e-01]\n [ 2.47340502e+00 -1.32073074e-01]\n [ 2.53008665e+00  6.02133456e-01]\n [ 2.95832053e-01 -3.34045508e-01]\n [ 4.33601547e-01 -9.40469240e-01]\n [ 5.43625132e-01  7.23852902e-01]\n [-1.24404140e+00  4.03473837e-01]\n [-3.14465713e-01  8.05971188e-01]\n [ 2.80805828e-01  3.18967408e-01]\n [-3.34288307e-01  2.15865712e-01]\n [ 1.27911145e+00 -7.88178282e-01]\n [-5.59170102e-01  7.12071351e-01]\n [ 4.18950798e-02 -5.68922430e-01]\n [ 4.27803064e-01 -9.49706996e-02]\n [ 3.94698536e-01  3.23723608e-01]\n [ 9.96796494e-01  9.11050207e-01]\n [ 1.51036049e+00 -5.31674880e-01]\n [ 1.47512149e+00  7.04954012e-01]\n [ 1.64750152e+00 -3.03493969e-01]\n [ 2.02183905e+00  1.43850482e-01]\n [ 6.27747418e-01  4.18568099e-01]\n [ 2.04714036e+00 -1.14919780e-01]\n [ 3.88129719e-01  1.09946871e-01]\n [-1.31316555e+00  6.78091746e-01]\n [ 2.72926826e-01  5.03834670e-01]\n [-3.06248147e-01  3.64257262e-01]\n [ 1.63415533e+00 -2.52351341e-01]\n [ 7.74635774e-01 -6.22440653e-01]\n [ 1.93954412e-01  1.05716709e+00]\n [ 8.08486195e-01 -7.67051276e-01]\n [ 1.93118782e+00  2.36788553e-01]\n [ 8.47523614e-01  6.60042759e-01]\n [ 5.15726937e-01 -3.47821601e-01]\n [ 2.00968186e-01  3.66592345e-01]\n [-8.43128465e-01  3.97869430e-01]\n [ 4.31296922e-01  4.46323623e-01]\n [ 4.20576195e-01 -5.64697873e-01]\n [ 6.85150409e-01  7.76327658e-01]\n [ 1.07846758e+00 -6.39893393e-01]\n [ 1.32529346e-01 -2.17376163e-02]\n [-2.29557611e-01  8.24366628e-01]\n [ 3.37137547e-01 -1.06918870e-01]\n [ 1.90023548e+00  6.96249951e-01]\n [ 1.74304711e-01  5.92384239e-01]\n [ 5.72167283e-01 -5.87818960e-01]\n [ 2.32287867e+00  8.71076592e-01]\n [ 6.18053301e-01 -9.11785286e-01]\n [-6.78066329e-01  7.49467436e-01]\n [ 6.85839313e-01  6.19399526e-01]\n [ 4.98868900e-01 -3.95868546e-01]\n [ 1.18828438e+00  7.99145965e-01]\n [ 2.79899835e+00 -6.39112338e-03]\n [-1.07392089e+00  8.62527283e-01]\n [ 1.05181328e+00 -2.89741699e-01]\n [-2.39577834e-01  7.84291406e-01]\n [ 2.05310880e+00  1.00839264e+00]\n [-7.90513590e-01  1.08341903e+00]\n [-4.93621465e-01  9.60498618e-01]\n [ 3.78797008e-01  5.23578422e-01]\n [ 4.02900542e-01  5.40688712e-01]\n [ 7.41734367e-01 -7.59879868e-01]\n [-3.69686751e-01  2.59150458e-01]\n [ 1.76570280e-02  7.05666327e-01]\n [ 7.16426229e-01  3.10907729e-01]\n [ 8.45559990e-02  2.53837860e-01]\n [ 1.55774058e+00  3.54279514e-02]\n [-3.34276872e-01  1.01980724e+00]\n [-1.21046915e-01 -9.08388899e-02]\n [ 1.59057223e+00  9.28946221e-03]\n [-7.87142196e-01  9.07055103e-01]\n [ 1.27519076e+00 -1.17431158e+00]\n [ 2.17841084e-01  6.58837194e-01]\n [ 1.86445091e+00 -2.57721907e-01]\n [ 2.95132064e-01 -2.78792488e-01]\n [ 2.25822470e-01  3.35672899e-01]\n [ 3.51034153e-01  2.84706277e-01]\n [-5.61395675e-01  6.35114044e-01]\n [ 1.38472867e-01  1.13485609e+00]\n [-1.95001613e-02  1.11556320e+00]\n [ 6.35356620e-01 -3.51281019e-01]\n [-2.64302961e-02  8.73594384e-01]\n [ 1.11930290e+00 -6.07656854e-01]\n [ 1.19609159e+00  3.22490466e-01]\n [ 1.70491525e+00 -2.75860786e-01]\n [ 2.57481800e-01 -5.39383846e-01]\n [-1.30199977e+00  6.53187519e-01]\n [ 1.75044030e+00  1.44641861e-01]\n [-8.63031460e-02  7.91761029e-01]\n [ 2.50168377e+00  7.76879655e-01]\n [ 4.07871533e-01 -3.42573838e-01]\n [-4.05387547e-01  5.39911475e-01]\n [ 1.30173265e-01  1.09442697e+00]\n [ 2.82035071e-01  1.04835431e+00]\n [ 2.74530128e-01 -1.42660544e-01]\n [ 1.82398104e-01  2.96612334e-02]\n [ 1.26017313e+00 -5.89217041e-01]\n [-2.66492596e-02  1.58396005e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred=sum(tree.predict(X[0]) for tree in (tree_reg1,tree_reg2,tree_reg3))"
   ]
  },
  {
   "source": [
    "We can get new predictions by simply adding the sums of previous predictions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Scikit Learn Gradient Boosted Trees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt= GradientBoostingRegressor(max_depth=2,n_estimators=3,learning_rate=1.0)\n",
    "gbrt.fit(X,y)"
   ]
  },
  {
   "source": [
    "Training with while searching for the optimal number of trees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, n_estimators=120)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "grbt = GradientBoostingRegressor(max_depth=2,n_estimators=120)\n",
    "grbt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [mean_squared_error(y_val,y_pred) for y_pred in grbt.staged_predict(X_val)]\n",
    "\n",
    "bst_n_estimators=np.argmin(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, n_estimators=55)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "grbt_best = GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators)\n",
    "grbt_best.fit(X_train,y_train)"
   ]
  },
  {
   "source": [
    "# Early Stopping When No Improvement Occurs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grbt = GradientBoostingRegressor(max_depth=2,warm_start=True)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up=0\n",
    "for n_estimators in range(1,120):\n",
    "    grbt.n_estimators=n_estimators\n",
    "    grbt.fit(X_train,y_train)\n",
    "    y_pred=grbt.predict(X_val)\n",
    "    val_error=mean_squared_error(y_val,y_pred)\n",
    "    if min_val_error < val_error:\n",
    "        min_val_error=val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break # Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-769b5d8957c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# xgb_reg = xgboost.XGBRegressor()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# xgb_reg.fit(X_train,y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# y_pred = xgb_reg.predict(X_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "# xgb_reg = xgboost.XGBRegressor()\n",
    "# xgb_reg.fit(X_train,y_train)\n",
    "# y_pred = xgb_reg.predict(X_val)\n",
    "\n",
    "# xgb_reg.fit(X_train,Y_train,\n",
    "#             eval_set = [(X_val,y_val)], early_stopping_rounds=2)\n",
    "# y_pred = xgb_reg.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### NOTE : The XGBOOST package is not available with the anaconda packages and should be an additional download."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Stacking"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}